#Crypto-Stock application of Granger causality in extremes 

#main function needed to be uploaded for this application is 'Extreme_causality_full_graph_estimate' - this function can be found at lines 200-500. 
#Note that this function slightly differs from the function in the main file, as we added a few improvements after this application was finished, but the core of the function remains the same

library("readxl")
library(igraph)


data_origin = read.csv(file = 'crypto/data_last_day.csv')
head(data_origin)

log_returns <- function(prices) {return(diff(log(prices)))}

data = c()
for (i in 1:14) {
  x = data_origin[data_origin$Asset_ID==i,4]
  x = log_returns(x)
  data = cbind(data,x ) 
}
data = as.data.frame(data)
names(data) = c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14')
head(data)


#Just the simple plot 
plot(data$x9, type = 'l', col=2, lty = 1, lwd = 2, xlab = 'Time [minutes]', ylab = 'Log-return values', main = 'IOTA and Binance')
lines(data$x1, type = 'l', lty = 1, lwd = 2)


data = abs(data)
lag_future=1

Estimated_graph=Extreme_causality_full_graph_estimate(w=data, lag_future = lag_future, p_value_computation = FALSE)



#We use igraph package to visualize it:
dumping_factor = 0; #First figure
dumping_factor = 0.2;  #Second figure

G=list(G= Estimated_graph$G, weights = Estimated_graph$weights)
G$G <- Estimated_graph$G[which(Estimated_graph$weights >= dumping_factor), ]; G$weights <- Estimated_graph$weights[which(Estimated_graph$weights >= dumping_factor)]
graph <- graph_from_edgelist(G$G)
E(graph)$edge.width <- 10*(G$weights)
V(graph)$name =  c("Binance Coin", "Bitcoin", "BCH", "Cardano", "Dogecoin", "EOS.IO", "Ethereum", "Ethereum Classic", "IOTA", "Litecoin", "Maker", "Monero","Stellar", "TRON" )


plot.igraph(graph, 
            layout = layout_with_fr(graph), 
            vertex.label = V(graph)$name, 
            edge.width = E(graph)$edge.width, 
            vertex.color = 'lightgrey', 
            vertex.label.cex = 1, 
            vertex.size =22, 
            main = 'Applying Algorithm 1, lag = 1 min')




#If you want to obtain the estimates based on p-values, change p_value_computation = TRUE. That will take a few days to compute, but you can just try out some specific edges that you are interested in
#For example, is there a line from x1->x2?
x = data$x1; y = data$x2; z = data.frame(data$x3, data$x4, data$x5, data$x6, data$x7, data$x8, data$x9, data$x10, data$x11, data$x12, data$x13, data$x14)
Extreme_causality_test(x = x, y = y, z = z,
                       lag_future = 30,
                       nu_x = nu_x,   q_y =q_y, q_z=q_z, lag_past = lag_past, p_value_computation = TRUE)





#We do the same with lag = 30
lag_future=30
Estimated_graph=Extreme_causality_full_graph_estimate(w=data, lag_future = lag_future, p_value_computation = FALSE)



#We use igraph package to visualize it:
dumping_factor = 0.3
G=list(G= Estimated_graph$G, weights = Estimated_graph$weights)
G$G <- Estimated_graph$G[which(Estimated_graph$weights >= dumping_factor), ]; G$weights <- Estimated_graph$weights[which(Estimated_graph$weights >= dumping_factor)]
graph <- graph_from_edgelist(G$G)
E(graph)$edge.width <- 10*(G$weights)
V(graph)$name =  c("Binance Coin", "Bitcoin", "BCH", "Cardano", "Dogecoin", "EOS.IO", "Ethereum", "Ethereum Classic", "IOTA", "Litecoin", "Maker", "Monero","Stellar", "TRON" )


plot.igraph(graph, 
            layout = layout_with_fr(graph), 
            vertex.label = V(graph)$name, 
            edge.width = E(graph)$edge.width, 
            vertex.color = 'lightgrey', 
            vertex.label.cex = 1, 
            vertex.size =22, 
            main = 'Applying Algorithm 1, lag = 1 min')





#This is just what ChatGPT gave us when we asked him to draw causal graph between the variables 


#Bitcoin --> Ethereum --> ERC-20 Tokens (e.g., Maker, IOTA, TRON, etc.)
#|           |
#             +--> Ethereum Classic
#|
#  +--> Litecoin --> Dogecoin
#|
#  +--> Monero
#|
#  +--> Binance Coin
#|
#  +--> Cardano --> Stellar
#|
#  +--> BCH
#|
#  +--> EOS.IO

















































































Extreme_causality_test = function(x, y, z=NULL, lag_future=1, lag_past=0, nu_x = 0.3, q_y = 0.2, q_z = 0.1, instant=FALSE, p_value_computation = FALSE, bootstrap_repetitions=50, q_F=0.5){
  
  n = length(x)
  z=data.frame(z)
  d = ncol(z) ;
  tau_y = q_y * n; tau_z = q_z * n
  
  
  
  F_u = function(imput, output){ifelse(output < quantile(imput, q_F), 0, (ecdf(imput)(output)))}
  #F_u = function(imput, output){ifelse(output < quantile(imput, q_F), 0, 1)}
  #F_u = function(imput, output){ifelse(output < quantile(imput, q_F), 0, 1)}
  #F_u = function(imput, output){return(ecdf(imput)(output))}
  
  
  CTC_baseline = function(x, y, z=NULL, lag_future=lag_future, lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant){
    
    run_future_max <- function(x, k=3, instant=TRUE){ #instant= do we want to consider Y_0?
      if (instant==TRUE) {q=0}else{q=1}
      
      n=length(x);  y=c()  
      for (i in 1:n) {y=rbind(y, max(x[(min(n,i+q)):(min(n,i+k))]))}
      
      return(y)
    }
    
    x_to_y_masking= c()
    for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y)
    x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)])) 
    
    if(d>0){ for (j in 1:d){  
      zz = c( rep(0, i-1), z[,j])
      x_to_y_masking= c(x_to_y_masking,  which(zz>sort(z[,j])[(n-tau_z)]))}
    }
    x_to_y_masking = unique(x_to_y_masking)
    }
    
    future_y = run_future_max(y, lag_future, instant = instant)
    #baseline1 =mean(F_u(y[-x_to_y_masking], future_y[-x_to_y_masking]))
    baseline2=mean(F_u(y, future_y[-x_to_y_masking]))
    
    return( baseline2  )
  }
  
  
  CTC_masked = function(x, y, z=NULL, lag_future, lag_past, tau_y, tau_z, instant){
    
    run_future_max <- function(x, k=3, instant=TRUE){ #instant= do we want to consider Y_0?
      if (instant==TRUE) {q=0}else{q=1}
      
      n=length(x);  y=c()  
      for (i in 1:n) {y=rbind(y, max(x[(min(n,i+q)):(min(n,i+k))]))}
      
      return(y)
    }
    
    
    x_to_y_masking= c()
    for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y)
    x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)])) 
    
    if(d>0){ for (j in 1:d){  
      zz = c( rep(0, i-1), z[,j])
      x_to_y_masking= c(x_to_y_masking,  which(zz>sort(z[,j])[(n-tau_z)]))}
    }
    x_to_y_masking = unique(x_to_y_masking)
    }
    
    n=length(x); k = round((n-length(x_to_y_masking))^(nu_x) )
    
    new_x = x[-x_to_y_masking]
    
    future_y = run_future_max(y, lag_future, instant = instant)
    
    future_y = future_y[-x_to_y_masking]
    
    top_x=which(new_x>=sort(new_x)[length(new_x)-k+1])
    
    
    #return( mean(F_u(y[-x_to_y_masking], future_y[top_x]))  )
    return( mean(F_u(y, future_y[top_x]))  )
    
  }
  
  
  
  
  switcher_for_test <- function(x, number_of_blocks=15){ #resampling block-wise
    
    n=nrow(x)
    m=n%/%number_of_blocks #length of one block
    
    y=c()
    for (i in 1:number_of_blocks) {#choose one random block with the beginning uniformly chosen from 1:(n-m)
      kocka=sample(1:(n-m), 1)
      for (j in 1:m) {
        y=rbind(y,x[kocka+j,])  #Add this block to our resampled series
      }
      
    }
    #what to do with the ending if it is not divisible? we just add one random block with smaller length to obtain times eris with length $n$ again
    if (ncol(x)==1) {  #Code for one-dimensional time series
      if(n%%number_of_blocks!=0){y=c(y,x[((number_of_blocks*m+1):n),])}} 
    else{
      if(n%%number_of_blocks!=0){
        k=n-number_of_blocks*m
        kocka=sample(1:(n-k), 1)
        
        for (j in 1:k) {
          y=rbind(y,x[kocka+j,])  
        }}
    }
    return(data.frame(y))
  }
  
  
  
  baseline = CTC_baseline(x, y, z=z, lag_future=lag_future, lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant)
  CTC = CTC_masked(x,y,z,lag_future=lag_future,lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant)
  
  
  if(p_value_computation == FALSE){
    if(CTC<=(1+baseline)/2) return(data.frame(output = 'No causality', CTC=CTC , baseline = baseline))
    if(CTC>(1+baseline)/2) return(data.frame(output = 'Evidence of causality', CTC=CTC , baseline = baseline))
  }
  
  #if(all(z == FALSE)) {
  #  x_to_y_masking= .Machine$integer.max
  #  for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y)
  #  x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)])) }
  #  x_to_y_masking = unique(x_to_y_masking)}
  
  
  #if(!all(z == FALSE)) {x_to_y_masking= .Machine$integer.max
  #for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y);zz = c( rep(0, i-1), z)
  #x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)]))
  #x_to_y_masking= c(x_to_y_masking,  which(zz>sort(z)[(n-tau_z)]))}
  #x_to_y_masking = unique(x_to_y_masking)
  #}
  
  
  if(CTC<=baseline){result = 0; result2=1} 
  if(CTC>baseline){
    result = c()
    result2 = c()
    # for (i in 1:bootstrap_repetitions) {
    #   new_time_series=switcher_for_test(data.frame(x[-x_to_y_masking],y[-x_to_y_masking]), number_of_blocks=number_of_blocks)
    #   result=c(result, CTC_masked(new_time_series[,1], new_time_series[,2], lag_future=lag_future,lag_past = 0, tau_y = 0, instant=instant ) )
    # }
    
    for (i in 1:bootstrap_repetitions) {
      new_time_series=switcher_for_test(data.frame(x,y,z), number_of_blocks=floor(sqrt(length(x))))
      tilde_x = new_time_series[,1] ;  tilde_y =new_time_series[,2] ; if(d==0){tilde_z = NULL};  if(d>0){tilde_z =  data.frame(new_time_series[,3:(d+2)])};  
      result  = c(result, CTC_masked(tilde_x, tilde_y, tilde_z, lag_future=lag_future,lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant ) )
      result2 = c(result2, CTC_baseline(tilde_x, tilde_y, tilde_z, lag_future=lag_future,lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant ) )
    }
  }
  
  
  output = 'No causality';  if(CTC>(1+baseline)/2)   output = 'Evidence of causality'; 
  return( data.frame( output=output, p_value_tail = mean(result <=  result2) , p_value_extreme = mean(result <=  (1+3*result2)/4), CTC=CTC , baseline = baseline))
}



Extreme_causality_full_graph_estimate = function(w, lag_future=1, lag_past=0, q_y = 0.2, q_z = 0.1, instant=FALSE, p_value_computation = FALSE, bootstrap_repetitions=50, q_F=0.5, nu_x = 0.3){
  
  m=ncol(w)
  
  find_parents = function(G, vertex){
    result = c()
    for (i in 1:nrow(G)) { 
      if(G[i,2]==vertex){result = c(result, G[i,1])}
    }
    return(result)
  }
  
  compute_edge_weights = function(CTC, baseline){ (CTC -((1+baseline)/2))/(1-((1+baseline)/2))  }
  
  #Step 1: Pairwise    
  G = c()  
  for (i in 1:m) {
    for (j in (1:m)[-i]) {
      x=w[,i];y=w[,j]
      CTC=Extreme_causality_test(x,y,z=NULL,  nu_x = nu_x,   q_y =q_y, q_z=q_z, lag_future = lag_future, lag_past = lag_past, p_value_computation = p_value_computation, q_F=q_F)
      if(CTC$output =='Evidence of causality') G=rbind(G, c(i,j))    
    }  
  }
  
  #Step 2: Multivariate  
  if( all(G == FALSE)  ){return('Result: Empty graph')}
  if( !all(G == FALSE)  ){ #if G is non-empty
    indexes_to_erase = .Machine$integer.max
    edges_weights = c()
    for (i in 1:nrow(G)) {
      x = w[,G[i,1]]
      y = w[,G[i,2]]
      
      z_indexes=intersect(find_parents(G, G[i,1]), find_parents(G, G[i,2]))  
      if(all(z_indexes == FALSE)) {z=NULL}  
      if(!all(z_indexes == FALSE)) {z=data.frame(w[,z_indexes])}  
      
      CTC=Extreme_causality_test(x,y,z=z,  nu_x = nu_x,   q_y =q_y, q_z=q_z, lag_future = lag_future, lag_past = lag_past, p_value_computation = p_value_computation, q_F=q_F)
      if(CTC$output == 'No causality'){ indexes_to_erase = c(indexes_to_erase, i)}else{ edges_weights = c(edges_weights, compute_edge_weights(CTC$CTC, CTC$baseline))}
    }}
  
  return(list(G = G[-indexes_to_erase,], weights = edges_weights))  
}











