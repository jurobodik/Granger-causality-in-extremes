#This code serves for reproducibility purposes concerning the simulations about the choice of hyper-parameters
#You need to first upload the function 'Extreme_causality_test' from lines 1-200. Note that this function is slightly different from the original main function in the main file, as more parameters are possible to change (and some minor changes in the main algorithm were made since)
#Lines 200-400 corresponds to the choice of q_F; that is, optimal choice of F
#Lines 400-600 corresponds to the choice of tau_X
#Lines 600-800 corresponds to the choice of tau_Y
#Lines 800-1000 corresponds to the choice of tau_Z
library(EnvStats) #To generate Pareto noise


Extreme_causality_test = function(x, y, z=NULL, lag_future=1, lag_past=0, nu_x = 0.3, q_y = 0.2, q_z = 0.1, instant=FALSE, p_value_computation = FALSE, bootstrap_repetitions=50, q_F=0.5){
  
  n = length(x)
  z=data.frame(z)
  d = ncol(z) ;
  tau_y = q_y * n; tau_z = q_z * n
  
  
  
  F_u = function(imput, output){ifelse(output < quantile(imput, q_F), 0, (ecdf(imput)(output)))}
  #F_u = function(imput, output){ifelse(output < quantile(imput, q_F), 0, 1)}
  #F_u = function(imput, output){ifelse(output < quantile(imput, q_F), 0, 1)}
  #F_u = function(imput, output){return(ecdf(imput)(output))}
  
  
  CTC_baseline = function(x, y, z=NULL, lag_future=lag_future, lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant){
    
    run_future_max <- function(x, k=3, instant=TRUE){ #instant= do we want to consider Y_0?
      if (instant==TRUE) {q=0}else{q=1}
      
      n=length(x);  y=c()  
      for (i in 1:n) {y=rbind(y, max(x[(min(n,i+q)):(min(n,i+k))]))}
      
      return(y)
    }
    
    x_to_y_masking= c()
    for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y)
    x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)])) 
    
    if(d>0){ for (j in 1:d){  
      zz = c( rep(0, i-1), z[,j])
      x_to_y_masking= c(x_to_y_masking,  which(zz>sort(z[,j])[(n-tau_z)]))}
    }
    x_to_y_masking = unique(x_to_y_masking)
    }
    
    future_y = run_future_max(y, lag_future, instant = instant)
    #baseline1 =mean(F_u(y[-x_to_y_masking], future_y[-x_to_y_masking]))
    baseline2=mean(F_u(y, future_y[-x_to_y_masking]))
    
    return( baseline2  )
  }
  
  
  CTC_masked = function(x, y, z=NULL, lag_future, lag_past, tau_y, tau_z, instant){
    
    run_future_max <- function(x, k=3, instant=TRUE){ #instant= do we want to consider Y_0?
      if (instant==TRUE) {q=0}else{q=1}
      
      n=length(x);  y=c()  
      for (i in 1:n) {y=rbind(y, max(x[(min(n,i+q)):(min(n,i+k))]))}
      
      return(y)
    }
    
    
    x_to_y_masking= c()
    for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y)
    x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)])) 
    
    if(d>0){ for (j in 1:d){  
      zz = c( rep(0, i-1), z[,j])
      x_to_y_masking= c(x_to_y_masking,  which(zz>sort(z[,j])[(n-tau_z)]))}
    }
    x_to_y_masking = unique(x_to_y_masking)
    }
    
    n=length(x); k = round((n-length(x_to_y_masking))^(nu_x) )
    
    new_x = x[-x_to_y_masking]
    
    future_y = run_future_max(y, lag_future, instant = instant)
    
    future_y = future_y[-x_to_y_masking]
    
    top_x=which(new_x>=sort(new_x)[length(new_x)-k+1])
    
    
    #return( mean(F_u(y[-x_to_y_masking], future_y[top_x]))  )
    return( mean(F_u(y, future_y[top_x]))  )
    
  }
  
  
  
  
  switcher_for_test <- function(x, number_of_blocks=15){ #resampling block-wise
    
    n=nrow(x)
    m=n%/%number_of_blocks #length of one block
    
    y=c()
    for (i in 1:number_of_blocks) {#choose one random block with the beginning uniformly chosen from 1:(n-m)
      kocka=sample(1:(n-m), 1)
      for (j in 1:m) {
        y=rbind(y,x[kocka+j,])  #Add this block to our resampled series
      }
      
    }
    #what to do with the ending if it is not divisible? we just add one random block with smaller length to obtain times eris with length $n$ again
    if (ncol(x)==1) {  #Code for one-dimensional time series
      if(n%%number_of_blocks!=0){y=c(y,x[((number_of_blocks*m+1):n),])}} 
    else{
      if(n%%number_of_blocks!=0){
        k=n-number_of_blocks*m
        kocka=sample(1:(n-k), 1)
        
        for (j in 1:k) {
          y=rbind(y,x[kocka+j,])  
        }}
    }
    return(data.frame(y))
  }
  
  
  
  baseline = CTC_baseline(x, y, z=z, lag_future=lag_future, lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant)
  CTC = CTC_masked(x,y,z,lag_future=lag_future,lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant)
  
  
  if(p_value_computation == FALSE){
    if(CTC<=(1+baseline)/2) return(data.frame(output = 'No causality', CTC=CTC , baseline = baseline))
    if(CTC>(1+baseline)/2) return(data.frame(output = 'Evidence of causality', CTC=CTC , baseline = baseline))
  }
  
  #if(all(z == FALSE)) {
  #  x_to_y_masking= .Machine$integer.max
  #  for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y)
  #  x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)])) }
  #  x_to_y_masking = unique(x_to_y_masking)}
  
  
  #if(!all(z == FALSE)) {x_to_y_masking= .Machine$integer.max
  #for (i in 1:(lag_past+1)) { yy = c( rep(0, i-1), y);zz = c( rep(0, i-1), z)
  #x_to_y_masking= c(x_to_y_masking,  which(yy>sort(y)[(n-tau_y)]))
  #x_to_y_masking= c(x_to_y_masking,  which(zz>sort(z)[(n-tau_z)]))}
  #x_to_y_masking = unique(x_to_y_masking)
  #}
  
  
  if(CTC<=baseline){result = 0; result2=1} 
  if(CTC>baseline){
    result = c()
    result2 = c()
    # for (i in 1:bootstrap_repetitions) {
    #   new_time_series=switcher_for_test(data.frame(x[-x_to_y_masking],y[-x_to_y_masking]), number_of_blocks=number_of_blocks)
    #   result=c(result, CTC_masked(new_time_series[,1], new_time_series[,2], lag_future=lag_future,lag_past = 0, tau_y = 0, instant=instant ) )
    # }
    
    for (i in 1:bootstrap_repetitions) {
      new_time_series=switcher_for_test(data.frame(x,y,z), number_of_blocks=floor(sqrt(length(x))))
      tilde_x = new_time_series[,1] ;  tilde_y =new_time_series[,2] ; if(d==0){tilde_z = NULL};  if(d>0){tilde_z =  data.frame(new_time_series[,3:(d+2)])};  
      result  = c(result, CTC_masked(tilde_x, tilde_y, tilde_z, lag_future=lag_future,lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant ) )
      result2 = c(result2, CTC_baseline(tilde_x, tilde_y, tilde_z, lag_future=lag_future,lag_past = lag_past, tau_y = tau_y, tau_z = tau_z, instant=instant ) )
    }
  }
  
  
  output = 'No causality';  if(CTC>(1+baseline)/2)   output = 'Evidence of causality'; 
  return( data.frame( output=output, p_value_tail = mean(result <=  result2) , p_value_extreme = mean(result <=  (1+3*result2)/4), CTC=CTC , baseline = baseline))
}




























#Simulations for q_F

#VAR model
result = c()
sekv = seq(0.01, 0.61, by=0.1) #This is the sequence for alpha in the Gaussian model
# sekv = seq(0.01, 0.21, by=0.05) #sequence for Pareto noise. Un-comment this line for the heavy-tailed case result

for (q in c(0, 0.3,  0.5,  0.7)) {
  result2=c()
  cat('Time remaining: ',  q, '\n')  
  
  for (alpha in sekv) {
    result1=c()
    
    for (k in 100:1) {
      n=500
      
      epsilon_x=rnorm(n, 0,1)  #Replace by rpareto(n, 1, 1) for the heavy-tailed case result
      epsilon_y=rnorm(n, 0,1)  #Replace by rpareto(n, 1, 1) for the heavy-tailed case result
      epsilon_z=rnorm(n, 0,1)  #Replace by rpareto(n, 1, 1) for the heavy-tailed case result
      
      x=rep(0, n);y=rep(0, n);z=rep(0, n)
      
      for (i in 3:n) {
        z[i]=0.5*z[i-1]  + epsilon_z[i]
        x[i]=0.5*x[i-1]  + 0.5*z[i-1] + epsilon_x[i]
        y[i]=0.5*y[i-1]  + 0.5*z[i-1] + alpha*x[i-1] + epsilon_y[i]
      }
      
      
      CTC1 = Extreme_causality_test(x,y,z,     q_y =0.1, q_z=0.1, lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=q)
      CTC2 = Extreme_causality_test(y,x,z,    q_y =0.1, q_z=0.1, lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=q)
      result1 = c(result1, sum(CTC1$output=='Evidence of causality', CTC2$output=='No causality'))
    }
    result2 = c(result2, sum(result1)) 
  }
  result = rbind(result, result2)
}



# Plot the lines
plot(result[1,]~sekv, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='alpha_x', ylab="Performance", main = 'VAR non-heavy-tailed case')
for (i in 2:nrow(result)) {
  lines(result[i,]~sekv, type = 'l', col=i, lwd=3, lty=i-1)
}


# Create legend
legend("bottomright", 
       legend=c("q_F=0", "q_F=0.3", "q_F=0.5",  "q_F=0.7"),
       col=c(1, 2, 3, 4),
       lty=c(1, 1, 2, 3), lwd=3)





#GARCH model
result = c()
sekv = seq(0.01, 0.41, by=0.075)  #This is the sequence for alpha
#sekv = seq(0.01, 5.01, by=1)  #sequence for normal noise


for (q in c(0, 0.3,  0.5,  0.7)) {
  result2=c()
  cat('Time remaining: ',  q, '\n')  
  
  for (alpha in sekv) {
    result1=c()
    
    
    for (k in 100:1) {
      n=500
      
      epsilon_x=rcauchy(n, 0,1)
      epsilon_y=rcauchy(n, 0,1)
      epsilon_z=rcauchy(n, 0,1)
      
      x=rep(0, n);y=rep(0, n);z=rep(0, n)
      
      for (i in 3:n) {
        z[i]=((0.1+ 0.1*z[i-1]^2)^(0.5))*epsilon_z[i]
        x[i]=((0.1+ 0.1*x[i-1]^2 +  0.1*z[i-1]^2)^(0.5))*epsilon_x[i]
        y[i]=((0.1+ 0.1*y[i-1]^2 +  0.1*z[i-1]^2 + alpha*x[i-1]^2 )^(0.5))*epsilon_y[i]
      }
      
      
      x=abs(x); y=abs(y); z=abs(z)
      CTC1 = Extreme_causality_test(x,y,z,     q_y =0.1, q_z=0.1, lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=q)
      CTC2 = Extreme_causality_test(y,x,z,    q_y =0.1, q_z=0.1, lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=q)
      result1 = c(result1, sum(CTC1$output=='Evidence of causality', CTC2$output=='No causality'))
    }
    result2 = c(result2, sum(result1)) 
  }
  result = rbind(result, result2)
}


# Plot the lines
plot(result[1,]~sekv, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='alpha_x', ylab="Performance", main = 'GARCH heavy-tailed case')
for (i in 2:nrow(result)) {
  lines(result[i,]~sekv, type = 'l', col=i, lwd=3, lty=i-1)
}


# Create legend
legend("bottomright", 
       legend=c("q_F=0", "q_F=0.3", "q_F=0.5",  "q_F=0.7"),
       col=c(1, 2, 3, 4),
       lty=c(1,1, 2, 3), lwd=3)

























































































#Simulations for k_n
#This function generate the considered 4 models
generate_series = function(n=500, heavy_tailed = TRUE, VAR_or_GARCH = 'VAR'){
  
  x=rep(0, n);y=rep(0, n);z=rep(0, n)
  
  if(heavy_tailed == FALSE & VAR_or_GARCH == 'VAR'){
    epsilon_x=rnorm(n, 0,1) 
    epsilon_y=rnorm(n, 0,1) 
    epsilon_z=rnorm(n, 0,1) 
    
    
    for (i in 3:n) {
      z[i]=0.5*z[i-1]  + epsilon_z[i]
      x[i]=0.5*x[i-1]  + 0.5*z[i-1] + epsilon_x[i]
      y[i]=0.5*y[i-1]  + 0.5*z[i-1] + 0.5*x[i-1] + epsilon_y[i]
    }
  }
  
  if(heavy_tailed == TRUE & VAR_or_GARCH == 'VAR'){
    epsilon_x=rpareto(n, 1,1) 
    epsilon_y=rpareto(n, 1,1) 
    epsilon_z=rpareto(n, 1,1) 
    
    
    for (i in 3:n) {
      z[i]=0.5*z[i-1]  + epsilon_z[i]
      x[i]=0.5*x[i-1]  + 0.5*z[i-1] + epsilon_x[i]
      y[i]=0.5*y[i-1]  + 0.5*z[i-1] + 0.1*x[i-1] + epsilon_y[i]
    }
  }
  
  
  
  if(heavy_tailed == FALSE & VAR_or_GARCH == 'GARCH'){
    epsilon_x=5*rnorm(n, 0,1) 
    epsilon_y=rnorm(n, 0,1) 
    epsilon_z=rnorm(n, 0,1) 
    
    
    for (i in 3:n) {
      z[i]=((0.1+ 0.1*z[i-1]^2)^(0.5))*epsilon_z[i]
      x[i]=((0.1+ 0.1*x[i-1]^2 +  0.1*z[i-1]^2)^(0.5))*epsilon_x[i]
      y[i]=((0.1+ 0.1*y[i-1]^2 +  0.1*z[i-1]^2 + 5*x[i-1]^2 )^(0.5))*epsilon_y[i]
    }
    x=abs(x); y=abs(y); z=abs(z)
  }
  
  if(heavy_tailed == TRUE & VAR_or_GARCH == 'GARCH'){
    epsilon_x=rcauchy(n, 0,1) 
    epsilon_y=rcauchy(n, 0,1) 
    epsilon_z=rcauchy(n, 0,1) 
    
    for (i in 3:n) {
      z[i]=((0.1+ 0.1*z[i-1]^2)^(0.5))*epsilon_z[i]
      x[i]=((0.1+ 0.1*x[i-1]^2 +  0.1*z[i-1]^2)^(0.5))*epsilon_x[i]
      y[i]=((0.1+ 0.1*y[i-1]^2 +  0.1*z[i-1]^2 + 0.5*x[i-1]^2 )^(0.5))*epsilon_y[i]
    }
    x=abs(x); y=abs(y); z=abs(z)
  }
  
  return(data.frame(x,y,z))
}




#Hidden confounder case

result = c()
sekv_n = c(200, 500, 10000)
sekv_tau = c(0.2, 0.3, 0.4, 0.5, 0.6)

for (nu_x in sekv_tau) {
  result2=c()
  cat('Time remaining: ',  nu_x, '\n')  
  
  for (n in sekv_n) {
    result1=c()
    for (heavy_tailed in c(FALSE, TRUE)) {
      for (VAR_or_GARCH in c('VAR', 'GARCH')) {  
        for (k in 50:1) {
          
          data = generate_series(n=n,  heavy_tailed = heavy_tailed, VAR_or_GARCH = VAR_or_GARCH)
          x=data$x; y=data$y; 
          
          CTC1 = Extreme_causality_test(x,y,z=NULL,     q_y =0.1,  lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, nu_x = nu_x)
          CTC2 = Extreme_causality_test(y,x,z=NULL,    q_y =0.1,  lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, nu_x = nu_x)
          
          result1 = c(result1, sum(CTC1$output=='Evidence of causality', CTC2$output=='No causality'))
        }}}
    result2 = c(result2, sum(result1)) 
  }
  result = rbind(result, result2)
}

result = result / 4
par(mfrow = c(1, 1))

# Plot the lines
plot(result[,1]~sekv_tau, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='k_n', ylab="Performance", main = 'Hidden confounder case')
for (i in 2:ncol(result)) {
  lines(result[,i]~sekv_tau, type = 'l', col=i, lwd=3, lty=i-1)
}

# Create legend
legend("bottomright", 
       legend=c("n=200", "n=400","n=600"),
       col=c(1, 2, 3),
       lty=c(1, 1, 2), lwd=3)








#No hidden confounder case
result = c()
sekv_n = c(200, 400, 600)
sekv_tau = c(0.2, 0.3, 0.4, 0.5, 0.6)



for (tau_x in sekv_tau) {
  result2=c()
  cat('Time remaining: ',  tau_x, '\n')  
  
  for (n in sekv_n) {
    result1=c()
    alpha = 0.5
    for (heavy_tailed in c(FALSE, TRUE)) {
      for (VAR_or_GARCH in c('VAR', 'GARCH')) {  
        for (k in 50:1) {
          
          data = generate_series(n=n,  heavy_tailed = heavy_tailed, VAR_or_GARCH = VAR_or_GARCH)
          x=data$x; y=data$y; z=data$z  
          
          CTC1 = Extreme_causality_test(x,y,z,     q_y =0.1, q_z=0.1, lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, tau_x = tau_x)
          CTC2 = Extreme_causality_test(y,x,z,    q_y =0.1, q_z=0.1, lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, tau_x = tau_x)
          
          result1 = c(result1, sum(CTC1$output=='Evidence of causality', CTC2$output=='No causality'))
        }}}
    result2 = c(result2, sum(result1)) 
  }
  result = rbind(result, result2)
}

result = result / 4
par(mfrow = c(1, 1))

# Plot the lines
plot(result[,1]~sekv_tau, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='k_n', ylab="Performance", main = 'Hidden confounder case')
for (i in 2:ncol(result)) {
  lines(result[,i]~sekv_tau, type = 'l', col=i, lwd=3, lty=i-1)
}

# Create legend
legend("bottomright", 
       legend=c("n=200", "n=400","n=600"),
       col=c(1, 2, 3),
       lty=c(1, 1, 2), lwd=3)





































#Graphs for optimal q_Y
generate_series = function(n=500, alpha_y=0.5,  heavy_tailed = TRUE, VAR_or_GARCH = 'VAR'){
  
  x=rep(0, n);y=rep(0, n);z=rep(0, n)
  
  if(heavy_tailed == FALSE & VAR_or_GARCH == 'VAR'){
    epsilon_x=rnorm(n, 0,1) 
    epsilon_y=rnorm(n, 0,1) 
    epsilon_z=rnorm(n, 0,1) 
    
    
    for (i in 3:n) {
      z[i]=0.5*z[i-1]  + epsilon_z[i]
      x[i]=0.5*x[i-1]  + 0.5*z[i-1] + epsilon_x[i]
      y[i]=alpha_y*y[i-1]  + 0.5*z[i-1] + 0.5*x[i-1] + epsilon_y[i]
    }
  }
  
  if(heavy_tailed == TRUE & VAR_or_GARCH == 'VAR'){
    epsilon_x=rpareto(n, 1,1) 
    epsilon_y=rpareto(n, 1,1) 
    epsilon_z=rpareto(n, 1,1) 
    
    
    for (i in 3:n) {
      z[i]=0.5*z[i-1]  + epsilon_z[i]
      x[i]=0.5*x[i-1]  + 0.5*z[i-1] + epsilon_x[i]
      y[i]=alpha_y*y[i-1]  + 0.5*z[i-1] + 0.1*x[i-1] + epsilon_y[i]
    }
  }
  
  
  
  if(heavy_tailed == FALSE & VAR_or_GARCH == 'GARCH'){
    epsilon_x=rnorm(n, 0,1) 
    epsilon_y=rnorm(n, 0,1) 
    epsilon_z=rnorm(n, 0,1) 
    
    
    for (i in 3:n) {
      z[i]=((0.1+ 0.1*z[i-1]^2)^(0.5))*epsilon_z[i]
      x[i]=((0.1+ 0.1*x[i-1]^2 +  0.1*z[i-1]^2)^(0.5))*epsilon_x[i]
      y[i]=((alpha_y/5+ 0.1*y[i-1]^2 +  0.1*z[i-1]^2 + 10*x[i-1]^2 )^(0.5))*epsilon_y[i]
    }
    x=abs(x); y=abs(y); z=abs(z)
  }
  
  if(heavy_tailed == TRUE & VAR_or_GARCH == 'GARCH'){
    epsilon_x=rcauchy(n, 0,1) 
    epsilon_y=rcauchy(n, 0,1) 
    epsilon_z=rcauchy(n, 0,1) 
    
    for (i in 3:n) {
      z[i]=((0.1+ 0.1*z[i-1]^2)^(0.5))*epsilon_z[i]
      x[i]=((0.1+ 0.1*x[i-1]^2 +  0.1*z[i-1]^2)^(0.5))*epsilon_x[i]
      y[i]=((alpha_y/5+ 0.1*y[i-1]^2 +  0.1*z[i-1]^2 + 0.5*x[i-1]^2 )^(0.5))*epsilon_y[i]
    }
    x=abs(x); y=abs(y); z=abs(z)
  }
  
  return(data.frame(x,y,z))
}



result = c()
n=500
sekv_alpha_y = c(0.1, 0.3, 0.5, 0.7)
sekv_q_y = c(0.01, 0.1, 0.2, 0.3, 0.4)



for (q_y in sekv_q_y) {
  result2=c()
  cat('Time remaining: ',  q_y, '\n')  
  
  for (alpha_y in sekv_alpha_y) {
    result1=c()
    for (heavy_tailed in c(FALSE, TRUE)) {
      for (VAR_or_GARCH in c('VAR', 'GARCH')) {  
        for (k in 50:1) {
          
          data = generate_series(n=n,  alpha_y =  alpha_y, heavy_tailed = heavy_tailed, VAR_or_GARCH = VAR_or_GARCH)
          x=data$x; y=data$y; z=data$z
          
          CTC1 = Extreme_causality_test(x,y,z=z,     q_y =q_y,  lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, nu_x = 0.3)
          CTC2 = Extreme_causality_test(y,x,z=z,     q_y =q_y,  lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, nu_x = 0.3)
          
          result1 = c(result1, sum(CTC1$output=='Evidence of causality', CTC2$output=='No causality'))
        }}}
    result2 = c(result2, sum(result1)) 
  }
  result = rbind(result, result2)
}

result = result / 4
result



par(mfrow = c(1, 1))

# Plot the lines
plot(result[,1]~sekv_q_y, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='k_n', ylab="Performance", main = 'n=500')
for (i in 2:ncol(result)) {
  lines(result[,i]~sekv_q_y, type = 'l', col=i, lwd=3, lty=i-1)
}

# Create legend
legend("bottomright", 
       legend=c("alpha_y=0.1", "alpha_y=0.3","alpha_y=0.5", 'alpha_y=0.7'),
       col=c(1, 2, 3, 4),
       lty=c(1, 1, 2, 3), lwd=3)


par(mfrow = c(1, 2))

# Plot the lines
plot(result[,1]~sekv_q_y, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='q_Y', ylab="Performance", main = 'n=500')
for (i in 2:ncol(result)) {
  lines(result[,i]~sekv_q_y, type = 'l', col=i, lwd=3, lty=i-1)
}

# Create legend
legend("bottomleft", 
       legend=c("alpha_y=0.1", "alpha_y=0.3","alpha_y=0.5", 'alpha_y=0.7'),
       col=c(1, 2, 3, 4),
       lty=c(1, 1, 2, 3), lwd=3)





result = result_10000

# Plot the lines
plot(result[,1]~sekv_q_y, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='q_Y', ylab="Performance", main = 'n=10000')
for (i in 2:ncol(result)) {
  lines(result[,i]~sekv_q_y, type = 'l', col=i, lwd=3, lty=i-1)
}

# Create legend
legend("bottomleft", 
       legend=c("alpha_y=0.1", "alpha_y=0.3","alpha_y=0.5", 'alpha_y=0.7'),
       col=c(1, 2, 3, 4),
       lty=c(1, 1, 2, 3), lwd=3)






















































#Graphs for optimal q_Z
#Here there is only heavy-tailed VAR model. The other models had roughly the same results; you can just rewrite the data-generating process by the function 'generate_series'
result = c()
n=1000
sekv_alpha_z = c(0.1, 0.5, 1, 2)
sekv_q_z = c(0, 0.01, 0.05, 0.1,  0.2, 0.5)



for (alpha_z in sekv_alpha_z) {
  cat('Time: ', alpha_z, '\n')
  result1=rep(0, length(sekv_q_z))
  for (k in 50:1) {
    
    
    epsilon_x=rpareto(n, 1,1)
    epsilon_y=rpareto(n, 1,1)
    epsilon_z=rpareto(n, 1,1)
    
    x=rep(0, n);y=rep(0, n);z=rep(0, n)
    
    for (i in 6:n) {
      z[i]=0.5*z[i-1]  + epsilon_z[i]
      x[i]=0.5*x[i-1]  + alpha_z*z[i-2] + epsilon_x[i]
      y[i]=0.5*y[i-1]  + alpha_z*z[i-1] + 0.1*x[i-1] + epsilon_y[i]
    }
    
    result2=c()
    for (q_z in sekv_q_z) {
      
      CTC1 = Extreme_causality_test(x,y,z=z,     q_z =q_z,  lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, nu_x = 0.3)
      CTC2 = Extreme_causality_test(y,x,z=z,     q_z =q_z,  lag_future = 1, lag_past = 0, p_value_computation = FALSE, q_F=0.5, nu_x = 0.3)
      
      
      result2 = c(result2, sum(CTC1$output=='Evidence of causality', CTC2$output=='No causality'))
    }
    result1 = result1+result2
  }
  result = rbind(result, result1)
}

result = result / 2

par(mfrow = c(1, 1))

# Plot the lines
plot(result[1,]~sekv_q_z, type = 'l', col=1, lwd=3, ylim=c(min(result), max(result)), xlab='q_Z', ylab="Performance", main = 'Choice of q_Z')
for (i in 2:nrow(result)) {
  lines(result[i,]~sekv_q_z, type = 'l', col=i, lwd=3, lty=i-1)
}

# Create legend
legend("bottomright", 
       legend=c('alpha_z=0.1', 'alpha_z=0.5', 'alpha_z=1', 'alpha_z=2'),
       col=c(1, 2, 3, 4),
       lty=c(1, 1, 2, 3), lwd=3)






